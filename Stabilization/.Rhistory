theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(angle = -90, hjust = 0))
library(dplyr)
library(tidyr)
library(ggplot2)
library(survey)
options(dplyr.summarise.inform = FALSE)
# read in data
cover = read.csv("C:/Users/courtney.s.couch/Documents/GitHub/December-2023-StRS-Stats-Workshop/Data/BenthicCover_SITE_analysisready.csv")
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
#options(survey.lonely.psu = "remove")
options(survey.lonely.psu = "adjust")
## define survey design
des = svydesign(id = ~1, strata = ~STRAT_CONC, weights = ~sw, data = mhi)
## replicate-weights survey design
# repdes = as.svrepdesign(des)
## calculate island/year means and SE
# standard design
isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = des, svymean)
# replicate-weights design
# isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = repdes, svymean)
# plot weighted mean coral cover by island and year
ggplot(isl_yearmean, aes(x = ANALYSIS_YEAR, y = CORAL, fill = ANALYSIS_YEAR)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"), width = 1, color = "black") +
geom_errorbar(aes(ymin = CORAL - se, ymax = CORAL + se), width = 0.2) +
facet_wrap(~ISLAND, nrow = 1) +
guides(fill = "none") +
theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(angle = -90, hjust = 0))
# fit Gaussian model
mod.1 = svyglm(PROP ~ ISLAND * ANALYSIS_YEAR, design = subset(des, GROUP=="CORAL"))
library(dplyr)
library(tidyr)
library(ggplot2)
library(survey)
options(dplyr.summarise.inform = FALSE)
# read in data
cover = read.csv("C:/Users/courtney.s.couch/Documents/GitHub/December-2023-StRS-Stats-Workshop/Data/BenthicCover_SITE_analysisready.csv")
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
#options(survey.lonely.psu = "remove")
options(survey.lonely.psu = "adjust")
## define survey design
des = svydesign(id = ~1, strata = ~STRAT_CONC, weights = ~sw, data = mhi)
## replicate-weights survey design
# repdes = as.svrepdesign(des)
## calculate island/year means and SE
# standard design
isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = des, svymean)
# replicate-weights design
# isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = repdes, svymean)
# plot weighted mean coral cover by island and year
ggplot(isl_yearmean, aes(x = ANALYSIS_YEAR, y = CORAL, fill = ANALYSIS_YEAR)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"), width = 1, color = "black") +
geom_errorbar(aes(ymin = CORAL - se, ymax = CORAL + se), width = 0.2) +
facet_wrap(~ISLAND, nrow = 1) +
guides(fill = "none") +
theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(angle = -90, hjust = 0))
# fit Gaussian model
mod.1 = svyglm(PROP ~ ISLAND * ANALYSIS_YEAR, design = subset(des, GROUP=="CORAL"))
library(dplyr)
library(tidyr)
library(ggplot2)
library(survey)
options(dplyr.summarise.inform = FALSE)
# read in data
cover = read.csv("C:/Users/courtney.s.couch/Documents/GitHub/December-2023-StRS-Stats-Workshop/Data/BenthicCover_SITE_analysisready.csv")
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
#options(survey.lonely.psu = "remove")
options(survey.lonely.psu = "adjust")
## define survey design
des = svydesign(id = ~1, strata = ~STRAT_CONC, weights = ~sw, data = mhi)
## replicate-weights survey design
# repdes = as.svrepdesign(des)
## calculate island/year means and SE
# standard design
isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = des, svymean)
# replicate-weights design
# isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = repdes, svymean)
# plot weighted mean coral cover by island and year
ggplot(isl_yearmean, aes(x = ANALYSIS_YEAR, y = CORAL, fill = ANALYSIS_YEAR)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"), width = 1, color = "black") +
geom_errorbar(aes(ymin = CORAL - se, ymax = CORAL + se), width = 0.2) +
facet_wrap(~ISLAND, nrow = 1) +
guides(fill = "none") +
theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(angle = -90, hjust = 0))
# fit Gaussian model
mod.1 = svyglm(CORAL ~ ISLAND * ANALYSIS_YEAR, design = des)
summary(mod.1)
#Test for significance of your fixed effects
car::Anova(mod.1, type = 3, test.statistic = "F")
# fit binomial model
mod.2 = svyglm(CORAL ~ ISLAND + ANALYSIS_YEAR, design = des, family = "binomial") # you will get an warning because it's expecting a 0/1, but it's ok the math will still work out
mod.3 = svyglm(CORAL ~ ISLAND * ANALYSIS_YEAR, design = des, family = "binomial")
# compare models (ignore eff.p and deltabar- telling you how AIC was adjusted)
AIC(mod.2, mod.3)
#guidance on AIC is that you should be using a combination of significance of predictors/likelihood ratio tests and AIC, use AIC carefully by itself
car::Anova(mod.1, type = 3, test.statistic = "F")
# ------------------------------------------------------------------------------------------------------------
# residual diagnostics
# Residuals tells you the difference between what the value was vs. what the model told you it was
# standardize by dividing by SD so you can identify certain points that were of concern
#resids = svydiags::svystdres(mod.3, stvar = "STRAT_CONC")$stdresids
resids = scale(mod.3$residuals)
resids = (mod.3$residuals - mean(mod.3$residuals))/sd(mod.3$residuals)
#Should we be concerned about this plot?
#In standard normal model, residuals should fall withing 2SD of mean
#Kyle, explain why we we should plot fitted residuals rather than use straight up plot(resids)
#When working with survey design don't use plot(mod.3)
plot(fitted(mod.3), resids)
hist(resids)
#
# VIF of min and max depth
1 / (1 - with(mhi, cor(new_MIN_DEPTH_M, new_MAX_DEPTH_M, use = "pairwise.complete.obs"))^2)
# highly correlated; would only include one in model
# plot max depth vs. proportion coral cover
ggplot(mhi, aes(x = new_MAX_DEPTH_M, y = CORAL)) + geom_point() + geom_smooth() + theme_bw()
# no evidence of non-linear trend, but let's add it to the model
# add max depth as linear term
mod.3.1 = svyglm(CORAL ~ ISLAND * ANALYSIS_YEAR + new_MAX_DEPTH_M, design = des, family = "binomial")
summary(mod.3.1)
# add max depth as 2nd degree polynomial
mod.3.2 = svyglm(CORAL ~ ISLAND * ANALYSIS_YEAR + poly(new_MAX_DEPTH_M, 2, raw = TRUE), design = des, family = "binomial")
# compare by AIC
AIC(mod.3.1, mod.3.2)
summary(mod.3.2)
# evidence of a non-linear trend in presence of other covariates that was not apparent in simple 2D plot
# increase to a 3rd degree polynomial
mod.3.3 = svyglm(CORAL ~ ISLAND * ANALYSIS_YEAR + poly(new_MAX_DEPTH_M, 3, raw = TRUE), design = des, family = "binomial")
# compare by AIC
AIC(mod.3.2, mod.3.3)
# no evidence of improved fit with 3rd degree-- we settle on 2nd degree polynomial
# summarize
anova(mod.3.2)
car::Anova(mod.3.2, type = 3, test.statistic = "F")
t(sapply(attr(mod.3.2$terms, "term.labels"), function(x) regTermTest(mod.3.2, x, method = "WorkingWald")[c("df", "ddf", "p")]))
# pseudo R-squared
jtools::summ(mod.3.2)
# planned comparisons
#Testing 2019 vs. 2010-12 in Kauai
#need to identify the reference levels for each categorical list
contr = multcomp::glht(mod.3.2, linfct = c("ANALYSIS_YEAR2019 = 0",
"ANALYSIS_YEAR2019 + ISLANDMaui:ANALYSIS_YEAR2019 = 0",
"ANALYSIS_YEAR2019 + ISLANDKauai:ANALYSIS_YEAR2019 = 0"))
summary(contr)
round(100 * (exp(confint(contr)$confint) - 1), 1)
6.5-2.3
4.2/6.5
86/336
4*10
210*40
/10
8400/10
50*210
9*11
23/3
23/4
69/4
213814+168442+181204
23.72/13.99
23.72-13.99
9.73/13.99
9.73/23.72
rm(list=ls())
library(gdata)             # needed for drop_levels()
library(reshape)           # reshape library inclues the cast() function used below
library(RODBC)            # to connect to oracle
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp.R")
#This script combines all historical raw CPC and CoralNet annotations, generates analysis ready data,
#generates site-level % cover for all sites then generates strata and weighed means at the sector and island-level
#in v3, we've made several updates to the pooling scheme and added in the 2022 data.
#Note- CRED/CREP/ESD made the switch from CPC to CoralNet in 2015, but some of the legacy 2012 imagery was analyzed in CoralNet
rm(list=ls())
library(gdata)             # needed for drop_levels()
library(reshape)           # reshape library inclues the cast() function used below
library(RODBC)            # to connect to oracle
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/fish_team_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/Islandwide Mean&Variance Functions.R")
#Climate data - this is from CPCE
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_BIA_CLIMATE_PERM.rdata")   #bia
cli$SITE<-SiteNumLeadingZeros(cli$SITE)
#BIA data - this is from CPCE
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_BIA_STR_RAW_NEW.rdata")   #bia
bia$SITE<-SiteNumLeadingZeros(bia$SITE)
#CNET data - from CoralNet
#These data contain human annotated data. There may be a small subset of robot annotated data.
#The robot annotations are included because the confidence threshold in CoralNet was set to 70-90% allowing the robot to annotate points when it was 70-90% certain.
#2019 NWHI data not in these view because it was analyzed as part of a bleaching dataset
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_CNET_Annotations.rdata") #load data
cnet<-select(cnet,-c("TYPE"))
head(cnet)
cnet$SITE<-as.factor(cnet$SITE)
cnet$SITE<-SiteNumLeadingZeros(cnet$SITE)
#Read in survey master and sector files
#sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Survey Master Prep/SURVEY_MASTER_w2013benthic.csv")
sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Survey Master Prep/SURVEY_MASTER.csv")
#Read in survey master and sector files
#sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Survey Master Prep/SURVEY_MASTER.csv")
sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
sectors<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/Sectors-Strata-Areas.csv")
#Temporary work around for merging in 2014-2017 NWHI data that hasn't been uploaded to Oracle yet- remove this once Michael has incorporated data
new.nw<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Raw Data from CoralNet/2014-2017_NWHI_CnetAnnotations_formatted.csv")
new.nw<-new.nw %>% drop_na(ROUNDID) #remove blank rows
new.cnet<-new.nw
class(new.cnet$DATE_)
class(new.cnet$DATE_TAKEN)
#Date conversations still not working
new.cnet$DATE_<-lubridate::mdy(new.cnet$DATE_)
new.cnet$DATE_TAKEN<-lubridate::ymd(new.cnet$DATE_TAKEN);head(new.cnet$DATE_TAKEN)
new.cnet$DATE_ANNOTATED<-lubridate::ymd_hms(new.cnet$DATE_ANNOTATED);head(new.cnet$DATE_ANNOTATED)
#########PLACEHOLDER Temporary work around for merging in 2023 SWAINS data
new.nw<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Raw Data from CoralNet/2014-2017_NWHI_CnetAnnotations_formatted.csv")
new.nw<-new.nw %>% drop_na(ROUNDID) #remove blank rows
new.cnet<-new.nw
class(new.cnet$DATE_)
class(new.cnet$DATE_TAKEN)
#Date conversations still not working
new.cnet$DATE_<-lubridate::mdy(new.cnet$DATE_)
new.cnet$DATE_TAKEN<-lubridate::ymd(new.cnet$DATE_TAKEN);head(new.cnet$DATE_TAKEN)
new.cnet$DATE_ANNOTATED<-lubridate::ymd_hms(new.cnet$DATE_ANNOTATED);head(new.cnet$DATE_ANNOTATED)
#combine old cnet and 2015 & 2017 nwhi cnet data
cnet<-rbind(cnet,new.cnet)
10*25
1000/250
300/30
25*30
#CREATE ADULT CLEAN ANALYSIS READY DATA----------------------------------------
# This script will clean the raw benthic REA data using method E that comes directly from the new data base application.
#Note- these data represent the revised data structure instituted in November 2018 and 2019. Several recent dead and condition columns were added
#These data only include surveys conducted between 2013-2020
#NOTE: Depth should not be used the in the raw data because the column was deprecated in Oracale and is inconsistent.
#Use depth data from SURVEY MASTER
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("./Functions/Benthic_Functions_newApp_vTAOfork.R")
963.13-62.74
rm(list=ls())
dir = Sys.info()[7]
setwd(paste0("C:/Users/", dir, "/Documents/GitHub/Restoration/Stabilization/"))
library(dplyr)
library(ggplot2)
#LOAD DATA
colony<-read.csv("Stablization_Colony_04172025.csv")
colony<- colony %>% select (-c(Notes:X.14))
bl.c<-colony %>% filter((Survey.Period=="Baseline") & (Treatment=="Control"))
bl.c$Survey.Period<-"T0_Post_Installation"
colony2<-colony %>% filter(Survey.Period!="Baseline")
colony3<-rbind(bl.c,colony2)
col.df<-as.data.frame(colony3 %>%
group_by(Survey.Period, Treatment,Plot_ID) %>%
summarise(n = n()))
View(col.df)
col.df<-col.df %>% filter(Treatment!="Reference")
col.df$Treatment <- factor(col.df$Treatment, levels = c("Control", "Mesh", "Boulder"))
ggplot(col.df,aes(Treatment,n))+
geom_boxplot(aes(fill=Survey.Period))+
#geom_jitter(width = 0.2, height = 0, size = 1, alpha = 0.8)
labs(x = "Treatment", y = "Colony Abundance")+
theme_minimal() +
theme(
axis.text = element_text(size = 12),
axis.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()  )+
watermark("DRAFT")
ggplot(col.df,aes(Treatment,n))+
geom_boxplot(aes(fill=Survey.Period))+
#geom_jitter(width = 0.2, height = 0, size = 1, alpha = 0.8)
labs(x = "Treatment", y = "Colony Abundance")+
theme_minimal() +
theme(
axis.text = element_text(size = 12),
axis.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()  )
lu<-read.csv("T:/Benthic/Data/Lookup Tables/2013-23_Taxa_MASTER_CONCORDANT_TAXON_NAME.csv")
head(lu)
gen<-lu %>% filter((REGION=="MHI") & (REGION=="OBS_YEAR"))
gen
gen<-lu %>% filter((REGION=="MHI") & (OBS_YEAR=="2024"))
gen
gen<-lu %>% filter((REGION=="MHI") & (OBS_YEAR=="2019"))
gen
lu<-read.csv("T:/Benthic/Data/Lookup Tables/Genus_lookup.csv")
lu
head(col.df)
head(colony)
colony<- colony %>% rename(SPCODE==Juvenile_Code)
colony<- colony %>% rename(Juvenile_Code==SPCODE)
head(colony)
colony<-read.csv("Stablization_Colony_04172025.csv")
colony<- colony %>% select (-c(Notes:X.14))
colony<- colony %>% rename(Juvenile_Code==SPCODE)
head(colony)
colony<- colony %>% rename(Juvenile_Code==SPCODE)
colony %>% rename(Juvenile_Code==SPCODE)
rm(list=ls())
dir = Sys.info()[7]
setwd(paste0("C:/Users/", dir, "/Documents/GitHub/Restoration/Stabilization/"))
library(dplyr)
library(ggplot2)
#LOAD DATA
colony<-read.csv("Stablization_Colony_04172025.csv")
colony<- colony %>% select (-c(Notes:X.14))
colony<- colony %>% rename(Juvenile_Code==SPCODE)
colony<- rename(colony, Juvenile_Code==SPCODE)
colony<- rename(colony, SPCODE==Juvenile_Code)
colony<- dplyr::rename(colony, SPCODE==Juvenile_Code)
?rename
head(iris)
colony<- rename(colony, SPCODE=Juvenile_Code)
head(colony)
colony<-left_join(colony,lu)
rm(list=ls())
dir = Sys.info()[7]
setwd(paste0("C:/Users/", dir, "/Documents/GitHub/Restoration/Stabilization/"))
lu<-read.csv("T:/Benthic/Data/Lookup Tables/Genus_lookup.csv")
library(dplyr)
library(ggplot2)
#LOAD DATA
colony<-read.csv("Stablization_Colony_04172025.csv")
colony<- colony %>% select (-c(Notes:X.14))
colony<- rename(colony, SPCODE=Juvenile_Code)
colony<-left_join(colony,lu)
head(colony)
#LOAD DATA
colony<-read.csv("Stablization_Colony_04172025.csv")
nrow(colony)
rm(list=ls())
dir = Sys.info()[7]
setwd(paste0("C:/Users/", dir, "/Documents/GitHub/Restoration/Stabilization/"))
lu<-read.csv("T:/Benthic/Data/Lookup Tables/Genus_lookup.csv")
library(dplyr)
library(ggplot2)
#LOAD DATA
colony<-read.csv("Stablization_Colony_04172025.csv")
colony<- colony %>% select (-c(Notes:X.14))
colony<- rename(colony, SPCODE=Juvenile_Code)
colony<-left_join(colony,lu)
nrow(colony)
tail(colony)
rm(list=ls())
dir = Sys.info()[7]
setwd(paste0("C:/Users/", dir, "/Documents/GitHub/Restoration/Stabilization/"))
lu<-read.csv("T:/Benthic/Data/Lookup Tables/Genus_lookup.csv")
library(dplyr)
library(ggplot2)
#LOAD DATA
colony<-read.csv("Stablization_Colony_04172025.csv")
colony<- colony %>% select (-c(Notes:X.14))
colony<- rename(colony, SPCODE=Juvenile_Code)
colony<-left_join(colony,lu)
bl.c<-colony %>% filter((Survey.Period=="Baseline") & (Treatment=="Control"))
bl.c$Survey.Period<-"T0_Post_Installation"
colony2<-colony %>% filter(Survey.Period!="Baseline")
colony3<-rbind(bl.c,colony2)
colony3
head(colony3)
col.gen<-as.data.frame(colony3 %>%
group_by(Survey.Period, Treatment,Plot_ID,TAXONNAME) %>%
summarise(n = n()))
View(col.gen)
col.gen<-col.gen %>% filter(Treatment!="Reference")
col.gen$Treatment <- factor(col.gen$Treatment, levels = c("Control", "Mesh", "Boulder"))
ggplot(col.gen,aes(Treatment,n, fill=TAXONNAME))+
geom_bar(position="stack", stat="identity")+
labs(x = "Treatment", y = "Colony Abundance")+
theme_minimal() +
theme(
axis.text = element_text(size = 12),
axis.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()  )
View(colony3)
col.gen<-as.data.frame(colony3 %>%
group_by(Survey.Period, Treatment,Plot_ID,GENUS_CODE) %>%
summarise(n = n()))
View(col.gen)
col.gen<-col.gen %>% filter(Treatment!="Reference")
col.gen$Treatment <- factor(col.gen$Treatment, levels = c("Control", "Mesh", "Boulder"))
ggplot(col.gen,aes(Treatment,n, fill=TAXONNAME))+
geom_bar(position="stack", stat="identity")+
labs(x = "Treatment", y = "Colony Abundance")+
theme_minimal() +
theme(
axis.text = element_text(size = 12),
axis.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()  )
col.gen<-as.data.frame(colony3 %>%
group_by(Survey.Period, Treatment,Plot_ID,GENUS_CODE) %>%
summarise(n = n()))
View(col.gen)
col.gen<-col.gen %>% filter(Treatment!="Reference")
col.gen$Treatment <- factor(col.gen$Treatment, levels = c("Control", "Mesh", "Boulder"))
ggplot(col.gen,aes(Treatment,n, fill=GENUS_CODE))+
geom_bar(position="stack", stat="identity")+
labs(x = "Treatment", y = "Colony Abundance")+
theme_minimal() +
theme(
axis.text = element_text(size = 12),
axis.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()  )
ggplot(col.gen,aes(Survey.Period,n, fill=GENUS_CODE))+
facet_grid(cols = vars(Treatment))+
geom_bar(position="stack", stat="identity")+
labs(x = "Treatment", y = "Colony Abundance")+
theme_minimal() +
theme(
axis.text = element_text(size = 12),
axis.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()  )
head(col.gen)
ggplot(col.gen,aes(Survey.Period,n, fill=GENUS_CODE))+
geom_bar(position="stack", stat="identity")+
facet_grid(cols = vars(Treatment))+
labs(x = "Treatment", y = "Colony Abundance")+
theme_minimal() +
theme(
axis.text = element_text(size = 12),
axis.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()  )
ggplot(col.gen,aes(Survey.Period,n, fill=GENUS_CODE))+
geom_bar(position="stack", stat="identity")+
facet_wrap(~Treatment)+
labs(x = "Treatment", y = "Colony Abundance")+
theme_minimal() +
theme(
axis.text = element_text(size = 12),
axis.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()  )
ggplot(col.gen,aes(Survey.Period,n, fill=GENUS_CODE))+
geom_bar(position="stack", stat="identity")+
facet_wrap(~Treatment)
ggplot(col.gen,aes(Survey.Period,n, fill=GENUS_CODE))+
geom_bar(position="stack", stat="identity")+
facet_wrap(~Treatment)+
labs(x = "Treatment", y = "Colony Abundance")+
#theme_minimal() +
theme(
axis.text = element_text(size = 12),
axis.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()  )
