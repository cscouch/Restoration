# compare models by AIC
AICsvyvglm(mod.zip)
AICsvyvglm(mod.nb)
# model biomass with Tweedie distribution (log-link)
mod.bm = svyglm(BIOMASS ~ ISLAND * OBS_YEAR + HumanDen, design = desf,
family = statmod::tweedie(var.power = 1.75, link.power = 0), maxit = 500)
AIC(mod.bm)
summary(mod.bm)
# ------------------------------------------------------------------------------------------------------------
# fit zero-inflated negative binomial model
# (warnings about lack of zero-inflation)
mod.zinb = svy_vglm(COUNT ~ ISLAND, family = zinegbinomial(), design = desf)
# residual diagnostics
residsf = svydiags::svystdres(mod.bm, stvar = "STRAT_CONC")$stdresids
plot(fitted(mod.bm), residsf)
hist(residsf)
# model biomass with Tweedie distribution (log-link)
mod.bm = svyglm(BIOMASS ~ ISLAND * OBS_YEAR + HumanDen, design = desf,
family = statmod::tweedie(var.power = 1.75, link.power = 0), maxit = 500)
AIC(mod.bm)
summary(mod.bm)
# ------------------------------------------------------------------------------------------------------------
# residual diagnostics
residsf = svydiags::svystdres(mod.bm, stvar = "STRAT_CONC")$stdresids
plot(fitted(mod.bm), residsf)
hist(residsf)
mod.bm = svyglm(BIOMASS ~ ISLAND * OBS_YEAR + HumanDen, design = desf,
family = statmod::tweedie(var.power = 1.5, link.power = 0), maxit = 500)
AIC(mod.bm)
# model biomass with Tweedie distribution (log-link)
mod.bm = svyglm(BIOMASS ~ ISLAND * OBS_YEAR + HumanDen, design = desf,
family = statmod::tweedie(var.power = 1.75, link.power = 0), maxit = 500)
AIC(mod.bm)
residsf = svydiags::svystdres(mod.bm, stvar = "STRAT_CONC")
plot(fitted(mod.bm), residsf)
# summarize (currently no support for svy_vglm models)
car::Anova(mod.bm, type = 3, test.statistic = "F")
t(sapply(attr(mod.bm$terms, "term.labels"), function(x) regTermTest(mod.bm, x, method = "LRT")[c("df", "ddf", "p")]))
# pseudo R-squared (currently no support for svy_vglm models)
jtools::summ(mod.bm)
# planned comparisons for differences in slopes (supports svy_vglm models)
contrf = multcomp::glht(mod.bm, linfct = c("ISLANDHawaii:OBS_YEAR = 0",
"ISLANDHawaii:OBS_YEAR - ISLANDLisianski:OBS_YEAR = 0",
"ISLANDHawaii:OBS_YEAR - ISLANDOahu:OBS_YEAR = 0"))
summary(contrf)
round(100 * (exp(confint(contrf)$confint) - 1), 1)
#Another strategy  is to do all comparisons and
con = emmeans::emtrents(mod.bm, "ISLAND",var = "OBS_VAR")
#Another strategy  is to do all comparisons and
con = emmeans::emtrends(mod.bm, "ISLAND",var = "OBS_VAR")
#Another strategy  is to do all comparisons and
con = emmeans::emtrends(mod.bm, "ISLAND",var = "OBS_YEAR")
con
pairs(cons)
pairs(con)
library(dplyr)
library(tidyr)
library(ggplot2)
library(survey)
options(dplyr.summarise.inform = FALSE)
# read in data
cover = read.csv("C:/Users/courtney.s.couch/Documents/GitHub/December-2023-StRS-Stats-Workshop/Data/BenthicCover_SITE_analysisready.csv")
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
#options(survey.lonely.psu = "remove")
options(survey.lonely.psu = "adjust")
## define survey design
des = svydesign(id = ~1, strata = ~STRAT_CONC, weights = ~sw, data = mhi)
## replicate-weights survey design
# repdes = as.svrepdesign(des)
## calculate island/year means and SE
# standard design
isl_yearmean = svyby(~PERCENT, ~ISLAND + ANALYSIS_YEAR, design = subset(des, GROUP=="CORAL"), svymean)
library(dplyr)
library(tidyr)
library(ggplot2)
library(survey)
options(dplyr.summarise.inform = FALSE)
# read in data
cover = read.csv("C:/Users/courtney.s.couch/Documents/GitHub/December-2023-StRS-Stats-Workshop/Data/BenthicCover_SITE_analysisready.csv")
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
#options(survey.lonely.psu = "remove")
options(survey.lonely.psu = "adjust")
## define survey design
des = svydesign(id = ~1, strata = ~STRAT_CONC, weights = ~sw, data = mhi)
## replicate-weights survey design
# repdes = as.svrepdesign(des)
## calculate island/year means and SE
# standard design
isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = des, svymean)
# replicate-weights design
# isl_yearmean = svyby(~PERCENT, ~ISLAND + ANALYSIS_YEAR, design = subset(repdes, GROUP=="CORAL"), svymean)
# plot weighted mean coral cover by island and year
ggplot(isl_yearmean, aes(x = ANALYSIS_YEAR, y = PERCENT, fill = ANALYSIS_YEAR)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"), width = 1, color = "black") +
geom_errorbar(aes(ymin = PERCENT - se, ymax = PERCENT + se), width = 0.2) +
facet_wrap(~ISLAND, nrow = 1) +
guides(fill = "none") +
theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(angle = -90, hjust = 0))
library(dplyr)
library(tidyr)
library(ggplot2)
library(survey)
options(dplyr.summarise.inform = FALSE)
# read in data
cover = read.csv("C:/Users/courtney.s.couch/Documents/GitHub/December-2023-StRS-Stats-Workshop/Data/BenthicCover_SITE_analysisready.csv")
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
#options(survey.lonely.psu = "remove")
options(survey.lonely.psu = "adjust")
## define survey design
des = svydesign(id = ~1, strata = ~STRAT_CONC, weights = ~sw, data = mhi)
## replicate-weights survey design
# repdes = as.svrepdesign(des)
## calculate island/year means and SE
# standard design
isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = des, svymean)
# replicate-weights design
# isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = repdes, svymean)
# plot weighted mean coral cover by island and year
ggplot(isl_yearmean, aes(x = ANALYSIS_YEAR, y = CORAL, fill = ANALYSIS_YEAR)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"), width = 1, color = "black") +
geom_errorbar(aes(ymin = CORAL - se, ymax = CORAL + se), width = 0.2) +
facet_wrap(~ISLAND, nrow = 1) +
guides(fill = "none") +
theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(angle = -90, hjust = 0))
# fit Gaussian model
mod.1 = svyglm(PROP ~ ISLAND * ANALYSIS_YEAR, design = subset(des, GROUP=="CORAL"))
library(dplyr)
library(tidyr)
library(ggplot2)
library(survey)
options(dplyr.summarise.inform = FALSE)
# read in data
cover = read.csv("C:/Users/courtney.s.couch/Documents/GitHub/December-2023-StRS-Stats-Workshop/Data/BenthicCover_SITE_analysisready.csv")
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
#options(survey.lonely.psu = "remove")
options(survey.lonely.psu = "adjust")
## define survey design
des = svydesign(id = ~1, strata = ~STRAT_CONC, weights = ~sw, data = mhi)
## replicate-weights survey design
# repdes = as.svrepdesign(des)
## calculate island/year means and SE
# standard design
isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = des, svymean)
# replicate-weights design
# isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = repdes, svymean)
# plot weighted mean coral cover by island and year
ggplot(isl_yearmean, aes(x = ANALYSIS_YEAR, y = CORAL, fill = ANALYSIS_YEAR)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"), width = 1, color = "black") +
geom_errorbar(aes(ymin = CORAL - se, ymax = CORAL + se), width = 0.2) +
facet_wrap(~ISLAND, nrow = 1) +
guides(fill = "none") +
theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(angle = -90, hjust = 0))
# fit Gaussian model
mod.1 = svyglm(PROP ~ ISLAND * ANALYSIS_YEAR, design = subset(des, GROUP=="CORAL"))
library(dplyr)
library(tidyr)
library(ggplot2)
library(survey)
options(dplyr.summarise.inform = FALSE)
# read in data
cover = read.csv("C:/Users/courtney.s.couch/Documents/GitHub/December-2023-StRS-Stats-Workshop/Data/BenthicCover_SITE_analysisready.csv")
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
#options(survey.lonely.psu = "remove")
options(survey.lonely.psu = "adjust")
## define survey design
des = svydesign(id = ~1, strata = ~STRAT_CONC, weights = ~sw, data = mhi)
## replicate-weights survey design
# repdes = as.svrepdesign(des)
## calculate island/year means and SE
# standard design
isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = des, svymean)
# replicate-weights design
# isl_yearmean = svyby(~CORAL, ~ISLAND + ANALYSIS_YEAR, design = repdes, svymean)
# plot weighted mean coral cover by island and year
ggplot(isl_yearmean, aes(x = ANALYSIS_YEAR, y = CORAL, fill = ANALYSIS_YEAR)) +
geom_bar(stat = "identity", position = position_dodge2(preserve = "single"), width = 1, color = "black") +
geom_errorbar(aes(ymin = CORAL - se, ymax = CORAL + se), width = 0.2) +
facet_wrap(~ISLAND, nrow = 1) +
guides(fill = "none") +
theme_bw() +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_text(angle = -90, hjust = 0))
# fit Gaussian model
mod.1 = svyglm(CORAL ~ ISLAND * ANALYSIS_YEAR, design = des)
summary(mod.1)
#Test for significance of your fixed effects
car::Anova(mod.1, type = 3, test.statistic = "F")
# fit binomial model
mod.2 = svyglm(CORAL ~ ISLAND + ANALYSIS_YEAR, design = des, family = "binomial") # you will get an warning because it's expecting a 0/1, but it's ok the math will still work out
mod.3 = svyglm(CORAL ~ ISLAND * ANALYSIS_YEAR, design = des, family = "binomial")
# compare models (ignore eff.p and deltabar- telling you how AIC was adjusted)
AIC(mod.2, mod.3)
#guidance on AIC is that you should be using a combination of significance of predictors/likelihood ratio tests and AIC, use AIC carefully by itself
car::Anova(mod.1, type = 3, test.statistic = "F")
# ------------------------------------------------------------------------------------------------------------
# residual diagnostics
# Residuals tells you the difference between what the value was vs. what the model told you it was
# standardize by dividing by SD so you can identify certain points that were of concern
#resids = svydiags::svystdres(mod.3, stvar = "STRAT_CONC")$stdresids
resids = scale(mod.3$residuals)
resids = (mod.3$residuals - mean(mod.3$residuals))/sd(mod.3$residuals)
#Should we be concerned about this plot?
#In standard normal model, residuals should fall withing 2SD of mean
#Kyle, explain why we we should plot fitted residuals rather than use straight up plot(resids)
#When working with survey design don't use plot(mod.3)
plot(fitted(mod.3), resids)
hist(resids)
#
# VIF of min and max depth
1 / (1 - with(mhi, cor(new_MIN_DEPTH_M, new_MAX_DEPTH_M, use = "pairwise.complete.obs"))^2)
# highly correlated; would only include one in model
# plot max depth vs. proportion coral cover
ggplot(mhi, aes(x = new_MAX_DEPTH_M, y = CORAL)) + geom_point() + geom_smooth() + theme_bw()
# no evidence of non-linear trend, but let's add it to the model
# add max depth as linear term
mod.3.1 = svyglm(CORAL ~ ISLAND * ANALYSIS_YEAR + new_MAX_DEPTH_M, design = des, family = "binomial")
summary(mod.3.1)
# add max depth as 2nd degree polynomial
mod.3.2 = svyglm(CORAL ~ ISLAND * ANALYSIS_YEAR + poly(new_MAX_DEPTH_M, 2, raw = TRUE), design = des, family = "binomial")
# compare by AIC
AIC(mod.3.1, mod.3.2)
summary(mod.3.2)
# evidence of a non-linear trend in presence of other covariates that was not apparent in simple 2D plot
# increase to a 3rd degree polynomial
mod.3.3 = svyglm(CORAL ~ ISLAND * ANALYSIS_YEAR + poly(new_MAX_DEPTH_M, 3, raw = TRUE), design = des, family = "binomial")
# compare by AIC
AIC(mod.3.2, mod.3.3)
# no evidence of improved fit with 3rd degree-- we settle on 2nd degree polynomial
# summarize
anova(mod.3.2)
car::Anova(mod.3.2, type = 3, test.statistic = "F")
t(sapply(attr(mod.3.2$terms, "term.labels"), function(x) regTermTest(mod.3.2, x, method = "WorkingWald")[c("df", "ddf", "p")]))
# pseudo R-squared
jtools::summ(mod.3.2)
# planned comparisons
#Testing 2019 vs. 2010-12 in Kauai
#need to identify the reference levels for each categorical list
contr = multcomp::glht(mod.3.2, linfct = c("ANALYSIS_YEAR2019 = 0",
"ANALYSIS_YEAR2019 + ISLANDMaui:ANALYSIS_YEAR2019 = 0",
"ANALYSIS_YEAR2019 + ISLANDKauai:ANALYSIS_YEAR2019 = 0"))
summary(contr)
round(100 * (exp(confint(contr)$confint) - 1), 1)
6.5-2.3
4.2/6.5
86/336
4*10
210*40
/10
8400/10
50*210
9*11
23/3
23/4
69/4
213814+168442+181204
23.72/13.99
23.72-13.99
9.73/13.99
9.73/23.72
rm(list=ls())
library(gdata)             # needed for drop_levels()
library(reshape)           # reshape library inclues the cast() function used below
library(RODBC)            # to connect to oracle
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp.R")
#This script combines all historical raw CPC and CoralNet annotations, generates analysis ready data,
#generates site-level % cover for all sites then generates strata and weighed means at the sector and island-level
#in v3, we've made several updates to the pooling scheme and added in the 2022 data.
#Note- CRED/CREP/ESD made the switch from CPC to CoralNet in 2015, but some of the legacy 2012 imagery was analyzed in CoralNet
rm(list=ls())
library(gdata)             # needed for drop_levels()
library(reshape)           # reshape library inclues the cast() function used below
library(RODBC)            # to connect to oracle
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/fish_team_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/Islandwide Mean&Variance Functions.R")
#Climate data - this is from CPCE
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_BIA_CLIMATE_PERM.rdata")   #bia
cli$SITE<-SiteNumLeadingZeros(cli$SITE)
#BIA data - this is from CPCE
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_BIA_STR_RAW_NEW.rdata")   #bia
bia$SITE<-SiteNumLeadingZeros(bia$SITE)
#CNET data - from CoralNet
#These data contain human annotated data. There may be a small subset of robot annotated data.
#The robot annotations are included because the confidence threshold in CoralNet was set to 70-90% allowing the robot to annotate points when it was 70-90% certain.
#2019 NWHI data not in these view because it was analyzed as part of a bleaching dataset
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_CNET_Annotations.rdata") #load data
cnet<-select(cnet,-c("TYPE"))
head(cnet)
cnet$SITE<-as.factor(cnet$SITE)
cnet$SITE<-SiteNumLeadingZeros(cnet$SITE)
#Read in survey master and sector files
#sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Survey Master Prep/SURVEY_MASTER_w2013benthic.csv")
sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Survey Master Prep/SURVEY_MASTER.csv")
#Read in survey master and sector files
#sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Survey Master Prep/SURVEY_MASTER.csv")
sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
sectors<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/Sectors-Strata-Areas.csv")
#Temporary work around for merging in 2014-2017 NWHI data that hasn't been uploaded to Oracle yet- remove this once Michael has incorporated data
new.nw<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Raw Data from CoralNet/2014-2017_NWHI_CnetAnnotations_formatted.csv")
new.nw<-new.nw %>% drop_na(ROUNDID) #remove blank rows
new.cnet<-new.nw
class(new.cnet$DATE_)
class(new.cnet$DATE_TAKEN)
#Date conversations still not working
new.cnet$DATE_<-lubridate::mdy(new.cnet$DATE_)
new.cnet$DATE_TAKEN<-lubridate::ymd(new.cnet$DATE_TAKEN);head(new.cnet$DATE_TAKEN)
new.cnet$DATE_ANNOTATED<-lubridate::ymd_hms(new.cnet$DATE_ANNOTATED);head(new.cnet$DATE_ANNOTATED)
#########PLACEHOLDER Temporary work around for merging in 2023 SWAINS data
new.nw<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Raw Data from CoralNet/2014-2017_NWHI_CnetAnnotations_formatted.csv")
new.nw<-new.nw %>% drop_na(ROUNDID) #remove blank rows
new.cnet<-new.nw
class(new.cnet$DATE_)
class(new.cnet$DATE_TAKEN)
#Date conversations still not working
new.cnet$DATE_<-lubridate::mdy(new.cnet$DATE_)
new.cnet$DATE_TAKEN<-lubridate::ymd(new.cnet$DATE_TAKEN);head(new.cnet$DATE_TAKEN)
new.cnet$DATE_ANNOTATED<-lubridate::ymd_hms(new.cnet$DATE_ANNOTATED);head(new.cnet$DATE_ANNOTATED)
#combine old cnet and 2015 & 2017 nwhi cnet data
cnet<-rbind(cnet,new.cnet)
rm(list=ls())
dir = Sys.info()[7]
setwd(paste0("C:/Users/", dir, "/Documents/GitHub/Restoration/Post-storm Response"))
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
library(ggsn)
library(ggspatial)
library(ggrepel)
library(lubridate)
library(hms)
library(tidyr)
### read in track and damage data
track <- read.csv("Test_track.csv")
dmg <- read.csv("DataEntryRapidDamageAssessment_Test.csv")
#Clean up track file and convert date time columns
track <- track %>%
dplyr::select(Latitude, Longitude, Time) %>%
separate(Time,into=c("Date", "Time2"),
sep=" ", convert = TRUE, extra = "merge") %>%
mutate(date = ymd(Date),
datetime_utc = as_datetime(paste(Date, Time2)),
datetime_hst = as_datetime(datetime_utc, tz = 'US/Hawaii'))%>%
separate(datetime_hst,into=c("d", "Time"),
sep=" ", convert = TRUE, extra = "merge")%>%
dplyr::select(Latitude, Longitude, Time)
head(track)
#Clean up track file and convert date time columns
dmg$Time <- as.POSIXct(dmg$Time,format="%H:%M:%S")
dmg <- dmg %>%
separate(Time,into=c("d", "Time"),
sep=" ", convert = TRUE, extra = "merge")%>%
dplyr::select(-c(Notes))
dmgmeta.cols<-colnames(dmg)
dmg.meta<-dmg %>% distinct(Dataset_Name,Organization,Topside_Data_Recorder,In.water_Observer,
Island,Sub.Island_Region,Survey_Type,GPS_Unit,GPS_Start,GPS_End,Tow_Dive_Number, Date)
dmg.meta
#Change NAs to 0(areas were damage wasn't recorded)
test<-left_join(track,dmg) %>%
replace(is.na(.),0)
head(test)
View(test)
rm(list=ls())
dir = Sys.info()[7]
setwd(paste0("C:/Users/", dir, "/Documents/GitHub/Restoration/Post-storm Response"))
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
library(ggsn)
library(ggspatial)
library(ggrepel)
library(lubridate)
library(hms)
library(tidyr)
### read in track and damage data
track <- read.csv("Test_track.csv")
dmg <- read.csv("DataEntryRapidDamageAssessment_Test.csv")
#Clean up track file and convert date time columns
track <- track %>%
dplyr::select(Latitude, Longitude, Time) %>%
separate(Time,into=c("Date", "Time2"),
sep=" ", convert = TRUE, extra = "merge") %>%
mutate(date = ymd(Date),
datetime_utc = as_datetime(paste(Date, Time2)),
datetime_hst = as_datetime(datetime_utc, tz = 'US/Hawaii'))%>%
separate(datetime_hst,into=c("d", "Time"),
sep=" ", convert = TRUE, extra = "merge")%>%
dplyr::select(Latitude, Longitude, Time)
head(track)
#Clean up track file and convert date time columns
dmg$Time <- as.POSIXct(dmg$Time,format="%H:%M:%S")
dmg <- dmg %>%
separate(Time,into=c("d", "Time"),
sep=" ", convert = TRUE, extra = "merge")%>%
dplyr::select(-c(Notes))
dmgmeta.cols<-colnames(dmg)
dmg.meta<-dmg %>% distinct(Dataset_Name,Organization,Topside_Data_Recorder,In.water_Observer,
Island,Sub.Island_Region,Survey_Type,GPS_Unit,GPS_Start,GPS_End,Tow_Dive_Number, Date)
dmg.meta
#Change NAs to 0(areas were damage wasn't recorded)
test<-left_join(track,dmg) %>%
replace(is.na(.),0)
head(test)
write.csv("testmerge.csv",test)
head(test)
write.csv(test,"testmerge.csv")
